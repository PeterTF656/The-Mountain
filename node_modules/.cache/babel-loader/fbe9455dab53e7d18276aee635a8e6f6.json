{"ast":null,"code":"var _jsxFileName = \"/Users/zelinpu/Dev/FacialLandmarkDetection/src/App.js\";\n// 1. Install dependencies DONE\n// 2. Import dependencies DONE\n// 3. Setup webcam and canvas DONE\n// 4. Define references to those DONE\n// 5. Load posenet DONE\n// 6. Detect function DONE\n// 7. Drawing utilities from tensorflow DONE\n// 8. Draw functions DONE\n// Face Mesh - https://github.com/tensorflow/tfjs-models/tree/master/facemesh\nimport React, { useRef, useEffect, useState } from \"react\";\nimport \"./App.css\";\nimport * as tf from \"@tensorflow/tfjs\"; // OLD MODEL\n//import * as facemesh from \"@tensorflow-models/facemesh\";\n// NEW MODEL\n\nimport * as facemesh from \"@tensorflow-models/face-landmarks-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\";\nimport { drawEyeMesh } from \"./eyeStepOne\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n  const [draw, setDraw] = useState(0);\n\n  const handleClick = () => setDraw(draw + 1); //  Load posenet\n\n\n  const runFacemesh = async () => {\n    // OLD MODEL\n    // const net = await facemesh.load({\n    //   inputResolution: { width: 640, height: 480 },\n    //   scale: 0.8,\n    // });\n    // NEW MODEL\n    const net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh);\n\n    if (draw === 0) {\n      setInterval(() => {\n        detect(net);\n        console.log(0);\n      }, 10);\n    } else {\n      setInterval(() => {\n        detect_1(net);\n        console.log(draw);\n      }, 10);\n    }\n  };\n\n  const detect = async net => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set video width\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight; // Set canvas width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight; // Make Detections\n      // OLD MODEL\n      //       const face = await net.estimateFaces(video);\n      // NEW MODEL\n\n      const face = await net.estimateFaces({\n        input: video\n      }); // console.log(face);\n      // for (let i = 0; i < face.length; i++) {\n      //   const keypoints = face[i].scaledMesh;\n      //   // Log facial keypoints.\n      //   for (let i = 0; i < keypoints.length; i++) {\n      //     const [x, y, z] = keypoints[i];\n      //     console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);\n      //   }\n      // }\n      // Get canvas context\n\n      const ctx = canvasRef.current.getContext(\"2d\");\n      requestAnimationFrame(() => {\n        drawMesh(face, ctx);\n      });\n    }\n  };\n\n  const detect_1 = async net => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set video width\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight; // Set canvas width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight; // Make Detections\n      // OLD MODEL\n      //       const face = await net.estimateFaces(video);\n      // NEW MODEL\n\n      const face = await net.estimateFaces({\n        input: video\n      }); // console.log(face);\n      // for (let i = 0; i < face.length; i++) {\n      //   const keypoints = face[i].scaledMesh;\n      //   // Log facial keypoints.\n      //   for (let i = 0; i < keypoints.length; i++) {\n      //     const [x, y, z] = keypoints[i];\n      //     console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);\n      //   }\n      // }\n      // Get canvas context\n\n      const ctx = canvasRef.current.getContext(\"2d\");\n      requestAnimationFrame(() => {\n        drawEyeMesh(face, ctx);\n      });\n    }\n  };\n\n  useEffect(() => {\n    runFacemesh();\n  }, [draw]);\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"App\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 143,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 144,\n      columnNumber: 7\n    }\n  }, \"the variable draw is \", draw), /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 145,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    style: {\n      right: 0\n    },\n    onClick: handleClick,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 146,\n      columnNumber: 7\n    }\n  }, \"run mesh\")), /*#__PURE__*/React.createElement(\"header\", {\n    className: \"App-header\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 152,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(Webcam, {\n    ref: webcamRef,\n    style: {\n      position: \"absolute\",\n      marginLeft: \"auto\",\n      marginRight: \"auto\",\n      left: 0,\n      right: 0,\n      textAlign: \"center\",\n      zindex: 9,\n      width: 640,\n      height: 480\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 153,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"canvas\", {\n    ref: canvasRef,\n    style: {\n      position: \"absolute\",\n      marginLeft: \"auto\",\n      marginRight: \"auto\",\n      left: 0,\n      right: 0,\n      textAlign: \"center\",\n      zindex: 9,\n      width: 640,\n      height: 480\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 168,\n      columnNumber: 9\n    }\n  })));\n}\n\nexport default App;","map":{"version":3,"sources":["/Users/zelinpu/Dev/FacialLandmarkDetection/src/App.js"],"names":["React","useRef","useEffect","useState","tf","facemesh","Webcam","drawMesh","drawEyeMesh","App","webcamRef","canvasRef","draw","setDraw","handleClick","runFacemesh","net","load","SupportedPackages","mediapipeFacemesh","setInterval","detect","console","log","detect_1","current","video","readyState","videoWidth","videoHeight","width","height","face","estimateFaces","input","ctx","getContext","requestAnimationFrame","right","position","marginLeft","marginRight","left","textAlign","zindex"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,EAAmCC,QAAnC,QAAmD,OAAnD;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB,C,CACA;AACA;AAEA;;AACA,OAAO,KAAKC,QAAZ,MAA0B,6CAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,SAASC,QAAT,QAAyB,aAAzB;AACA,SAASC,WAAT,QAA4B,cAA5B;;AAEA,SAASC,GAAT,GAAe;AACb,QAAMC,SAAS,GAAGT,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMU,SAAS,GAAGV,MAAM,CAAC,IAAD,CAAxB;AACA,QAAM,CAACW,IAAD,EAAOC,OAAP,IAAkBV,QAAQ,CAAC,CAAD,CAAhC;;AAEA,QAAMW,WAAW,GAAG,MAAMD,OAAO,CAACD,IAAI,GAAC,CAAN,CAAjC,CALa,CAOb;;;AACA,QAAMG,WAAW,GAAG,YAAY;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,UAAMC,GAAG,GAAG,MAAMX,QAAQ,CAACY,IAAT,CAAcZ,QAAQ,CAACa,iBAAT,CAA2BC,iBAAzC,CAAlB;;AACA,QAAIP,IAAI,KAAK,CAAb,EAAgB;AAChBQ,MAAAA,WAAW,CAAC,MAAM;AACdC,QAAAA,MAAM,CAACL,GAAD,CAAN;AACAM,QAAAA,OAAO,CAACC,GAAR,CAAY,CAAZ;AACH,OAHU,EAGR,EAHQ,CAAX;AAID,KALC,MAKK;AACLH,MAAAA,WAAW,CAAC,MAAM;AAChBI,QAAAA,QAAQ,CAACR,GAAD,CAAR;AACAM,QAAAA,OAAO,CAACC,GAAR,CAAYX,IAAZ;AACH,OAHY,EAGV,EAHU,CAAX;AAID;AACA,GAnBD;;AAqBA,QAAMS,MAAM,GAAG,MAAOL,GAAP,IAAe;AAC5B,QACE,OAAON,SAAS,CAACe,OAAjB,KAA6B,WAA7B,IACAf,SAAS,CAACe,OAAV,KAAsB,IADtB,IAEAf,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA;AACA,YAAMD,KAAK,GAAGhB,SAAS,CAACe,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGlB,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGnB,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJA,CAMA;;AACAnB,MAAAA,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAlB,MAAAA,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC,CARA,CAUA;;AACAlB,MAAAA,SAAS,CAACc,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAjB,MAAAA,SAAS,CAACc,OAAV,CAAkBM,MAAlB,GAA2BF,WAA3B,CAZA,CAcA;AACA;AACA;AACA;;AACA,YAAMG,IAAI,GAAG,MAAMhB,GAAG,CAACiB,aAAJ,CAAkB;AAACC,QAAAA,KAAK,EAACR;AAAP,OAAlB,CAAnB,CAlBA,CAmBA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AACA,YAAMS,GAAG,GAAGxB,SAAS,CAACc,OAAV,CAAkBW,UAAlB,CAA6B,IAA7B,CAAZ;AACAC,MAAAA,qBAAqB,CAAC,MAAI;AAAC9B,QAAAA,QAAQ,CAACyB,IAAD,EAAOG,GAAP,CAAR;AAAoB,OAA1B,CAArB;AACD;AACF,GAxCD;;AA0CA,QAAMX,QAAQ,GAAG,MAAOR,GAAP,IAAe;AAC9B,QACE,OAAON,SAAS,CAACe,OAAjB,KAA6B,WAA7B,IACAf,SAAS,CAACe,OAAV,KAAsB,IADtB,IAEAf,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA;AACA,YAAMD,KAAK,GAAGhB,SAAS,CAACe,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGlB,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGnB,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJA,CAMA;;AACAnB,MAAAA,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAlB,MAAAA,SAAS,CAACe,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC,CARA,CAUA;;AACAlB,MAAAA,SAAS,CAACc,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAjB,MAAAA,SAAS,CAACc,OAAV,CAAkBM,MAAlB,GAA2BF,WAA3B,CAZA,CAcA;AACA;AACA;AACA;;AACA,YAAMG,IAAI,GAAG,MAAMhB,GAAG,CAACiB,aAAJ,CAAkB;AAACC,QAAAA,KAAK,EAACR;AAAP,OAAlB,CAAnB,CAlBA,CAmBA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;;AACA,YAAMS,GAAG,GAAGxB,SAAS,CAACc,OAAV,CAAkBW,UAAlB,CAA6B,IAA7B,CAAZ;AACAC,MAAAA,qBAAqB,CAAC,MAAI;AAAC7B,QAAAA,WAAW,CAACwB,IAAD,EAAOG,GAAP,CAAX;AAAuB,OAA7B,CAArB;AACD;AACF,GAxCD;;AA0CAjC,EAAAA,SAAS,CAAC,MAAI;AACVa,IAAAA,WAAW;AACd,GAFQ,EAEP,CAACH,IAAD,CAFO,CAAT;AAKA,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAA2BA,IAA3B,CADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACA;AACE,IAAA,KAAK,EAAE;AAAC0B,MAAAA,KAAK,EAAE;AAAR,KADT;AAEE,IAAA,OAAO,EAAExB,WAFX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADA,CAFF,eASE;AAAQ,IAAA,SAAS,EAAC,YAAlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,MAAD;AACE,IAAA,GAAG,EAAEJ,SADP;AAEE,IAAA,KAAK,EAAE;AACL6B,MAAAA,QAAQ,EAAE,UADL;AAELC,MAAAA,UAAU,EAAE,MAFP;AAGLC,MAAAA,WAAW,EAAE,MAHR;AAILC,MAAAA,IAAI,EAAE,CAJD;AAKLJ,MAAAA,KAAK,EAAE,CALF;AAMLK,MAAAA,SAAS,EAAE,QANN;AAOLC,MAAAA,MAAM,EAAE,CAPH;AAQLd,MAAAA,KAAK,EAAE,GARF;AASLC,MAAAA,MAAM,EAAE;AATH,KAFT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAgBE;AACE,IAAA,GAAG,EAAEpB,SADP;AAEE,IAAA,KAAK,EAAE;AACL4B,MAAAA,QAAQ,EAAE,UADL;AAELC,MAAAA,UAAU,EAAE,MAFP;AAGLC,MAAAA,WAAW,EAAE,MAHR;AAILC,MAAAA,IAAI,EAAE,CAJD;AAKLJ,MAAAA,KAAK,EAAE,CALF;AAMLK,MAAAA,SAAS,EAAE,QANN;AAOLC,MAAAA,MAAM,EAAE,CAPH;AAQLd,MAAAA,KAAK,EAAE,GARF;AASLC,MAAAA,MAAM,EAAE;AATH,KAFT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAhBF,CATF,CADF;AA2CD;;AAED,eAAetB,GAAf","sourcesContent":["// 1. Install dependencies DONE\n// 2. Import dependencies DONE\n// 3. Setup webcam and canvas DONE\n// 4. Define references to those DONE\n// 5. Load posenet DONE\n// 6. Detect function DONE\n// 7. Drawing utilities from tensorflow DONE\n// 8. Draw functions DONE\n\n// Face Mesh - https://github.com/tensorflow/tfjs-models/tree/master/facemesh\n\nimport React, { useRef, useEffect, useState } from \"react\";\nimport \"./App.css\";\nimport * as tf from \"@tensorflow/tfjs\";\n// OLD MODEL\n//import * as facemesh from \"@tensorflow-models/facemesh\";\n\n// NEW MODEL\nimport * as facemesh from \"@tensorflow-models/face-landmarks-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\";\nimport { drawEyeMesh } from \"./eyeStepOne\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n  const [draw, setDraw] = useState(0);\n\n  const handleClick = () => setDraw(draw+1)\n\n  //  Load posenet\n  const runFacemesh = async () => {\n    // OLD MODEL\n    // const net = await facemesh.load({\n    //   inputResolution: { width: 640, height: 480 },\n    //   scale: 0.8,\n    // });\n    // NEW MODEL\n    const net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh);\n    if (draw === 0) {\n    setInterval(() => {\n        detect(net);\n        console.log(0)\n    }, 10);\n  } else {\n    setInterval(() => {\n      detect_1(net);\n      console.log(draw)\n  }, 10);\n  }\n  };\n\n  const detect = async (net) => {\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      // OLD MODEL\n      //       const face = await net.estimateFaces(video);\n      // NEW MODEL\n      const face = await net.estimateFaces({input:video});\n      // console.log(face);\n      // for (let i = 0; i < face.length; i++) {\n      //   const keypoints = face[i].scaledMesh;\n  \n      //   // Log facial keypoints.\n      //   for (let i = 0; i < keypoints.length; i++) {\n      //     const [x, y, z] = keypoints[i];\n  \n      //     console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);\n      //   }\n      // }\n\n      // Get canvas context\n      const ctx = canvasRef.current.getContext(\"2d\");\n      requestAnimationFrame(()=>{drawMesh(face, ctx)});\n    }\n  };\n\n  const detect_1 = async (net) => {\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      // OLD MODEL\n      //       const face = await net.estimateFaces(video);\n      // NEW MODEL\n      const face = await net.estimateFaces({input:video});\n      // console.log(face);\n      // for (let i = 0; i < face.length; i++) {\n      //   const keypoints = face[i].scaledMesh;\n  \n      //   // Log facial keypoints.\n      //   for (let i = 0; i < keypoints.length; i++) {\n      //     const [x, y, z] = keypoints[i];\n  \n      //     console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);\n      //   }\n      // }\n\n      // Get canvas context\n      const ctx = canvasRef.current.getContext(\"2d\");\n      requestAnimationFrame(()=>{drawEyeMesh(face, ctx)});\n    }\n  };\n\n  useEffect(()=>{\n      runFacemesh();\n  },[draw]);\n  \n\n  return (\n    <div className=\"App\">\n      <div>the variable draw is {draw}</div>\n      <div>\n      <button \n        style={{right: 0}}\n        onClick={handleClick}>\n        run mesh\n      </button>\n      </div>\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}